{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenize\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH='./raw/scikit-learn/sklearn/decomposition/_factor_analysis.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_list = []\n",
    "with open(FILEPATH, 'rb') as f:\n",
    "    for tok in tokenize.tokenize(f.readline):\n",
    "        if tok.type == 3:\n",
    "            comment_list.append((tok.start[0], tok.end[0], tok.string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./index/scikit-learn/sklearn/decomposition/_factor_analysis.json', 'r') as f:\n",
    "    file_content = json.loads(f.read())\n",
    "ln_fdef = {}\n",
    "function_params = {}\n",
    "for fd in file_content['FunctionDef']:\n",
    "    for ln in file_content['FunctionDef'][fd]['lineno']:\n",
    "        if ln not in ln_fdef:\n",
    "            ln_fdef[ln] = []\n",
    "        ln_fdef[ln].append(fd)\n",
    "    function_params[fd] = file_content['FunctionDef'][fd]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfunc_pairs = []\n",
    "for clns, clne, cs in comment_list:\n",
    "    if clns-1 in ln_fdef:\n",
    "        for f in ln_fdef[clns-1]:\n",
    "            cfunc_pairs.append((f, cs))\n",
    "    if clne+1 in ln_fdef:\n",
    "        for f in ln_fdef[clne+1]:\n",
    "            cfunc_pairs.append((f, cs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self', 'X', 'y']\n",
      "\"\"\"Fit the FactorAnalysis model to X using SVD based approach.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            Training data.\n",
      "\n",
      "        y : Ignored\n",
      "            Ignored parameter.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        self : object\n",
      "            FactorAnalysis class instance.\n",
      "        \"\"\"\n",
      "['self', 'X']\n",
      "\"\"\"Apply dimensionality reduction to X using the model.\n",
      "\n",
      "        Compute the expected mean of the latent variables.\n",
      "        See Barber, 21.2.33 (or Bishop, 12.66).\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            Training data.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        X_new : ndarray of shape (n_samples, n_components)\n",
      "            The latent variables of X.\n",
      "        \"\"\"\n",
      "['self']\n",
      "\"\"\"Compute data covariance with the FactorAnalysis model.\n",
      "\n",
      "        ``cov = components_.T * components_ + diag(noise_variance)``\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        cov : ndarray of shape (n_features, n_features)\n",
      "            Estimated covariance of data.\n",
      "        \"\"\"\n",
      "['self']\n",
      "\"\"\"Compute data precision matrix with the FactorAnalysis model.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        precision : ndarray of shape (n_features, n_features)\n",
      "            Estimated precision of data.\n",
      "        \"\"\"\n",
      "['self', 'X']\n",
      "\"\"\"Compute the log-likelihood of each sample.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : ndarray of shape (n_samples, n_features)\n",
      "            The data.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        ll : ndarray of shape (n_samples,)\n",
      "            Log-likelihood of each sample under the current model.\n",
      "        \"\"\"\n",
      "['self', 'X', 'y']\n",
      "\"\"\"Compute the average log-likelihood of the samples.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : ndarray of shape (n_samples, n_features)\n",
      "            The data.\n",
      "\n",
      "        y : Ignored\n",
      "            Ignored parameter.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        ll : float\n",
      "            Average log-likelihood of the samples under the current model.\n",
      "        \"\"\"\n",
      "['self', 'components', 'n_components', 'tol']\n",
      "\"Rotate the factor analysis solution.\"\n",
      "['self']\n",
      "\"\"\"Number of transformed output features.\"\"\"\n",
      "['components', 'method', 'tol', 'max_iter']\n",
      "\"\"\"Return rotated components.\"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Provides comment-function pairs\n",
    "for func, comment in cfunc_pairs:\n",
    "    print(function_params[func])\n",
    "    print(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join('./index/', \"file_key.txt\")) as f:\n",
    "#         j = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parameters_from_func_description(func_description):\n",
    "    returns_loc = func_description.find('Returns')\n",
    "    if returns_loc != -1:\n",
    "        func_description = func_description[:returns_loc]\n",
    "    \n",
    "    func_description = func_description.replace('\\\\', '')\n",
    "        \n",
    "    parameters = {}\n",
    "    line_split_description = func_description.split('\\n')\n",
    "    for line_no, x in enumerate(line_split_description):\n",
    "        print(line_no, x)\n",
    "        if ':' in x:\n",
    "            cur_index = line_no\n",
    "            \n",
    "            while line_split_description[cur_index].strip() != '' and cur_index < len(line_split_description):\n",
    "                cur_index += 1\n",
    "                \n",
    "            parameters[x.split(':')[0].strip()] = ' '.join(line_split_description[line_no:cur_index]).strip()\n",
    "                \n",
    "            \n",
    "            \n",
    "    return parameters\n",
    "        \n",
    "\n",
    "def get_parameter_definition_locations(json_filepath, function_name):\n",
    "    DEBUG = True\n",
    "    \n",
    "    raw_filepath = json_filepath.replace('.json', '.py')\n",
    "    comment_list = []\n",
    "    with open(os.path.join('./raw', raw_filepath), 'rb') as f:\n",
    "        for tok in tokenize.tokenize(f.readline):\n",
    "            if tok.type == 3:\n",
    "                comment_list.append((tok.start[0], tok.end[0], tok.string))\n",
    "                \n",
    "    with open(os.path.join('./index', json_filepath), 'r') as f:\n",
    "        file_content = json.loads(f.read())\n",
    "    ln_fdef = {}\n",
    "    function_params = {}\n",
    "    for fd in file_content['FunctionDef']:\n",
    "        for ln in file_content['FunctionDef'][fd]['lineno']:\n",
    "            if ln not in ln_fdef:\n",
    "                ln_fdef[ln] = []\n",
    "            ln_fdef[ln].append(fd)\n",
    "        function_params[fd] = file_content['FunctionDef'][fd]['params']\n",
    "        \n",
    "    cfunc_pairs = {}\n",
    "    for clns, clne, cs in comment_list:\n",
    "        if clns-1 in ln_fdef:\n",
    "            for f in ln_fdef[clns-1]:\n",
    "                cfunc_pairs[f] = cs\n",
    "        if clne+1 in ln_fdef:\n",
    "            for f in ln_fdef[clne+1]:\n",
    "                cfunc_pairs[f] = cs\n",
    "                \n",
    "    if DEBUG:\n",
    "        for func, comment in cfunc_pairs.items():\n",
    "            print(func)\n",
    "            print(function_params[func])\n",
    "            print(comment)\n",
    "        print('\\n')\n",
    "    \n",
    "    func_comments = cfunc_pairs[function_name]\n",
    "    param_description_map = extract_parameters_from_func_description(func_comments)\n",
    "    param_location_map = {}\n",
    "    \n",
    "    if DEBUG:\n",
    "        print('Parameters for function: {}'.format(function_name))\n",
    "    for param_name in param_description_map:\n",
    "        param_description = param_description_map[param_name]\n",
    "        if DEBUG:\n",
    "            print(param_name, ':', param_description)\n",
    "        param_location_map[param_name] = set(['builtin']) # TODO: Search for the type of the parameter across multiple files\n",
    "        \n",
    "    return param_location_map\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__iter__\n",
      "['self']\n",
      "\"\"\"Iterate over the points in the grid.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        params : iterator over dict of str to any\n",
      "            Yields dictionaries mapping each estimator parameter to one of its\n",
      "            allowed values.\n",
      "        \"\"\"\n",
      "__len__\n",
      "['self']\n",
      "\"\"\"Number of points that will be sampled.\"\"\"\n",
      "__getitem__\n",
      "['self', 'ind']\n",
      "\"\"\"Get the parameters that would be ``ind``th in iteration\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        ind : int\n",
      "            The iteration index\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        params : dict of str to any\n",
      "            Equal to list(self)[ind]\n",
      "        \"\"\"\n",
      "_estimator_has\n",
      "['attr']\n",
      "\"\"\"Check if we can delegate a method to the underlying estimator.\n",
      "\n",
      "    Calling a prediction method will only be available if `refit=True`. In\n",
      "    such case, we check first the fitted best estimator. If it is not\n",
      "    fitted, we check the unfitted estimator.\n",
      "\n",
      "    Checking the unfitted estimator allows to use `hasattr` on the `SearchCV`\n",
      "    instance even before calling `fit`.\n",
      "    \"\"\"\n",
      "score\n",
      "['self', 'X', 'y']\n",
      "\"\"\"Return the score on the given data, if the estimator has been refit.\n",
      "\n",
      "        This uses the score defined by ``scoring`` where provided, and the\n",
      "        ``best_estimator_.score`` method otherwise.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            Input data, where `n_samples` is the number of samples and\n",
      "            `n_features` is the number of features.\n",
      "\n",
      "        y : array-like of shape (n_samples, n_output) \\\n",
      "            or (n_samples,), default=None\n",
      "            Target relative to X for classification or regression;\n",
      "            None for unsupervised learning.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        score : float\n",
      "            The score defined by ``scoring`` if provided, and the\n",
      "            ``best_estimator_.score`` method otherwise.\n",
      "        \"\"\"\n",
      "score_samples\n",
      "['self', 'X']\n",
      "\"\"\"Call score_samples on the estimator with the best found parameters.\n",
      "\n",
      "        Only available if ``refit=True`` and the underlying estimator supports\n",
      "        ``score_samples``.\n",
      "\n",
      "        .. versionadded:: 0.24\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : iterable\n",
      "            Data to predict on. Must fulfill input requirements\n",
      "            of the underlying estimator.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        y_score : ndarray of shape (n_samples,)\n",
      "            The ``best_estimator_.score_samples`` method.\n",
      "        \"\"\"\n",
      "predict\n",
      "['self', 'X']\n",
      "\"\"\"Call predict on the estimator with the best found parameters.\n",
      "\n",
      "        Only available if ``refit=True`` and the underlying estimator supports\n",
      "        ``predict``.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : indexable, length n_samples\n",
      "            Must fulfill the input assumptions of the\n",
      "            underlying estimator.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        y_pred : ndarray of shape (n_samples,)\n",
      "            The predicted labels or values for `X` based on the estimator with\n",
      "            the best found parameters.\n",
      "        \"\"\"\n",
      "predict_proba\n",
      "['self', 'X']\n",
      "\"\"\"Call predict_proba on the estimator with the best found parameters.\n",
      "\n",
      "        Only available if ``refit=True`` and the underlying estimator supports\n",
      "        ``predict_proba``.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : indexable, length n_samples\n",
      "            Must fulfill the input assumptions of the\n",
      "            underlying estimator.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      "            Predicted class probabilities for `X` based on the estimator with\n",
      "            the best found parameters. The order of the classes corresponds\n",
      "            to that in the fitted attribute :term:`classes_`.\n",
      "        \"\"\"\n",
      "predict_log_proba\n",
      "['self', 'X']\n",
      "\"\"\"Call predict_log_proba on the estimator with the best found parameters.\n",
      "\n",
      "        Only available if ``refit=True`` and the underlying estimator supports\n",
      "        ``predict_log_proba``.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : indexable, length n_samples\n",
      "            Must fulfill the input assumptions of the\n",
      "            underlying estimator.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      "            Predicted class log-probabilities for `X` based on the estimator\n",
      "            with the best found parameters. The order of the classes\n",
      "            corresponds to that in the fitted attribute :term:`classes_`.\n",
      "        \"\"\"\n",
      "decision_function\n",
      "['self', 'X']\n",
      "\"\"\"Call decision_function on the estimator with the best found parameters.\n",
      "\n",
      "        Only available if ``refit=True`` and the underlying estimator supports\n",
      "        ``decision_function``.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : indexable, length n_samples\n",
      "            Must fulfill the input assumptions of the\n",
      "            underlying estimator.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        y_score : ndarray of shape (n_samples,) or (n_samples, n_classes) \\\n",
      "                or (n_samples, n_classes * (n_classes-1) / 2)\n",
      "            Result of the decision function for `X` based on the estimator with\n",
      "            the best found parameters.\n",
      "        \"\"\"\n",
      "transform\n",
      "['self', 'X']\n",
      "\"\"\"Call transform on the estimator with the best found parameters.\n",
      "\n",
      "        Only available if the underlying estimator supports ``transform`` and\n",
      "        ``refit=True``.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : indexable, length n_samples\n",
      "            Must fulfill the input assumptions of the\n",
      "            underlying estimator.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        Xt : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "            `X` transformed in the new space based on the estimator with\n",
      "            the best found parameters.\n",
      "        \"\"\"\n",
      "inverse_transform\n",
      "['self', 'Xt']\n",
      "\"\"\"Call inverse_transform on the estimator with the best found params.\n",
      "\n",
      "        Only available if the underlying estimator implements\n",
      "        ``inverse_transform`` and ``refit=True``.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        Xt : indexable, length n_samples\n",
      "            Must fulfill the input assumptions of the\n",
      "            underlying estimator.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "            Result of the `inverse_transform` function for `Xt` based on the\n",
      "            estimator with the best found parameters.\n",
      "        \"\"\"\n",
      "n_features_in_\n",
      "['self']\n",
      "\"\"\"Number of features seen during :term:`fit`.\n",
      "\n",
      "        Only available when `refit=True`.\n",
      "        \"\"\"\n",
      "classes_\n",
      "['self']\n",
      "\"\"\"Class labels.\n",
      "\n",
      "        Only available when `refit=True` and the estimator is a classifier.\n",
      "        \"\"\"\n",
      "_run_search\n",
      "['self', 'evaluate_candidates']\n",
      "\"\"\"Search n_iter candidates from param_distributions\"\"\"\n",
      "_check_refit_for_multimetric\n",
      "['self', 'scores']\n",
      "\"\"\"Check `refit` is compatible with `scores` is valid\"\"\"\n",
      "_select_best_index\n",
      "['refit', 'refit_metric', 'results']\n",
      "\"\"\"Select index of the best combination of hyperparemeters.\"\"\"\n",
      "fit\n",
      "['self', 'X', 'y', 'groups', 'fit_params']\n",
      "\"\"\"Run fit with all sets of parameters.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "\n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            Training vector, where `n_samples` is the number of samples and\n",
      "            `n_features` is the number of features.\n",
      "\n",
      "        y : array-like of shape (n_samples, n_output) \\\n",
      "            or (n_samples,), default=None\n",
      "            Target relative to X for classification or regression;\n",
      "            None for unsupervised learning.\n",
      "\n",
      "        groups : array-like of shape (n_samples,), default=None\n",
      "            Group labels for the samples used while splitting the dataset into\n",
      "            train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "            instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
      "\n",
      "        **fit_params : dict of str -> object\n",
      "            Parameters passed to the `fit` method of the estimator.\n",
      "\n",
      "            If a fit parameter is an array-like whose length is equal to\n",
      "            `num_samples` then it will be split across CV groups along with `X`\n",
      "            and `y`. For example, the :term:`sample_weight` parameter is split\n",
      "            because `len(sample_weights) = len(X)`.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        self : object\n",
      "            Instance of fitted estimator.\n",
      "        \"\"\"\n",
      "_store\n",
      "['key_name', 'array', 'weights', 'splits', 'rank']\n",
      "\"\"\"A small helper to store the scores/times to the cv_results_\"\"\"\n",
      "\n",
      "\n",
      "0 \"\"\"Return the score on the given data, if the estimator has been refit.\n",
      "1 \n",
      "2         This uses the score defined by ``scoring`` where provided, and the\n",
      "3         ``best_estimator_.score`` method otherwise.\n",
      "4 \n",
      "5         Parameters\n",
      "6         ----------\n",
      "7         X : array-like of shape (n_samples, n_features)\n",
      "8             Input data, where `n_samples` is the number of samples and\n",
      "9             `n_features` is the number of features.\n",
      "10 \n",
      "11         y : array-like of shape (n_samples, n_output) \n",
      "12             or (n_samples,), default=None\n",
      "13             Target relative to X for classification or regression;\n",
      "14             None for unsupervised learning.\n",
      "15 \n",
      "16         \n",
      "Parameters for function: score\n",
      "X : X : array-like of shape (n_samples, n_features)             Input data, where `n_samples` is the number of samples and             `n_features` is the number of features.\n",
      "y : y : array-like of shape (n_samples, n_output)              or (n_samples,), default=None             Target relative to X for classification or regression;             None for unsupervised learning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'X': {'builtin'}, 'y': {'builtin'}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_parameter_definition_locations('scikit-learn/sklearn/model_selection/_search.json', 'score')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e32f703e4b4aeee2270df2522a490ac6a60a6bb0e1bf2eab687b01239260a1c9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
